# -*- coding: utf-8 -*-
# Date       ï¼š2023/7/27
# Author     ï¼šMahy
# Descriptionï¼š
"""
æµç¨‹ï¼š
ä¸Šä¼ æ–‡ä»¶
1ã€è¯»å–æ–‡ä»¶ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
2ã€ç”Ÿæˆæ‘˜è¦
3ã€æ‹¼æ¥æˆä¸Šä¸‹æ–‡é—®ç­”å¯¹ {åŸæ–‡æ®µï¼šåŸæ–‡æ®µä¸Šä¸‹1è¡Œ}
4ã€é€å…¥FAISSå»ºç«‹ç´¢å¼•ï¼ˆæ˜¯å¦ä½¿ç”¨BertModelè¿›è¡Œembeddingï¼Ÿï¼‰

æé—®
1ã€æŸ¥æ‰¾ä¸é—®é¢˜æœ€ç›¸ä¼¼çš„ä¸Šä¸‹æ–‡ï¼Œè¿”å›èƒŒæ™¯æ®µè½
2ã€å°†ç›¸ä¼¼æ®µè½ä¸å†å²æ®µè½æ‹¼æ¥æˆtext(Q,A)å½¢å¼é€å…¥ChatGLM-6Bï¼Œè¿”å›ç­”æ¡ˆ
"""
import yaml
import time
import json
import gradio as gr
import asyncio
import requests
from pathlib import Path
from sentence_transformers import SentenceTransformer as SBert
from query2glm import ChatGLM
from processFile.fileProcess import ProcessBook



# create a static directory to store the static files
static_dir = Path('C:/Users/haoyangma/Desktop/practice/ChatTest/static')
static_dir.mkdir(parents=True, exist_ok=True)

with open("config.yaml") as f:
    config = yaml.safe_load(f)

encode_model = SBert(config['encode_model_path'])
glm_chater = ChatGLM(chat_url=config['chatglm6b_url'], faiss_path=config['faiss_path'], encode_model=encode_model)
global c_range_id
history_id_dic = {}  # {id: history_list}
c_range_id_dic = {}  # {æ–‡ä»¶åï¼šmd5_id}


# TODO è®¾è®¡æ— æ–‡ä»¶ä¸Šä¼ çš„æƒ…å†µ
# èŠå¤©çª—å£æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
def user(query, history, doc_list):  # è¾“å…¥è¾“å‡ºä¸ºmsg_btnçš„inputså’Œoutputs
    global c_range_id
    global c_range_id_dic
    # è·å–c_range_id
    if doc_list != "":
        c_range_id = c_range_id_dic[doc_list]
        history += [[query, None]]
    return "", history

def get_pdf(pdf_path, target_url):
    data = {"pdf_filename": pdf_path}
    payload = json.dumps(data, ensure_ascii=False).encode("utf-8")
    headers = {'Content-Type': 'application/json'}
    response = requests.request("post", target_url, headers=headers, data=payload)
    result = json.loads(response.text)["out_html"]
    return result

# èŠå¤©çª—å£æ˜¾ç¤ºæœºå™¨è¿”å›
def bot(history):  # è¾“å…¥è¾“å‡ºå‡ä¼ ç»™chatbotæ§ä»¶
    global c_range_id
    global file_dropdown
    global history_id_dic
    query = history[-1][0]
    if query[-1] not in [",", ".", "?", "!", "ï¼Œ", "ã€‚", "ï¼Ÿ", "ï¼"]:
        query1 = query + "ï¼Ÿ"
    else:
        query1 = query
    if c_range_id == "":
        response = "è¯·å¯¼å…¥æ–‡ä»¶"
    else:
        response = asyncio.run(glm_chater.generate(c_range_id, query1, history=history_id_dic[c_range_id]))
    history_id_dic[c_range_id].append([query1, response])
    # æ‰“å­—æœºæ•ˆæœ
    history[-1][1] = ""
    for character in response:
        history[-1][1] += character
        time.sleep(0.02)
        yield history


# ä¸Šä¼ æ–‡ä»¶
def add_file(file, doc_list):
    global c_range_id
    global c_range_id_dic
    global history_id_dic
    preprocess = ProcessBook(encode_model, **config['header_and_footer'])
    c_range_id = preprocess.upload(config['faiss_path'], file.name)
    doc_name = file.name.split("/")[-1]
    c_range_id_dic[doc_name] = c_range_id
    doc_list = list(c_range_id_dic.keys())
    pdf_html = get_pdf(file.name, config['pdf_url'])
    if c_range_id not in history_id_dic:  # åˆæ¬¡ä¸Šä¼ ï¼Œåˆå§‹åŒ–æ–‡ä»¶history
        history_id_dic[c_range_id] = []
    return gr.Dropdown.update(choices=doc_list, value=doc_name), gr.HTML.update(value=pdf_html)


# é¡µé¢å¯åŠ¨æ‰§è¡Œçš„å†…å®¹
def load(doc_list):
    global c_range_id
    global c_range_id_dic
    global history_id_dic
    doc_list = list(c_range_id_dic.keys())
    default_pdf = get_pdf(config['default_pdf'], config['pdf_url'])
    for key in c_range_id_dic.keys():
        # å°è¯•æ‰¾åˆ°value
        if c_range_id_dic[key] == c_range_id:
            doc_name = key
            return gr.Dropdown.update(choices=doc_list, value=doc_name), gr.HTML.update(value=default_pdf)
    # ä¸å­˜åœ¨åˆé€‚çš„valueåˆ™ç”¨æˆ·é€‰æ‹©
    return gr.Dropdown.update(choices=doc_list), gr.HTML.update(value=default_pdf)


with gr.Blocks() as demo:

    with gr.Row(variant='panel'):
        with gr.Column(scale=3):
            file_dropdown = gr.Dropdown(
                choices=list(c_range_id_dic.keys()),
                show_label=False,
                interactive=True
            ).style(container=False)
        with gr.Column(scale=0.35):
            upload_button = gr.UploadButton("ä¸Šä¼ æ–‡æ¡£ ğŸ“", file_types=["file"])

    with gr.Row().style(equal_height=True):
        # æ˜¾ç¤ºæ–‡æ¡£
        with gr.Column(variant='panel'):
            file_display = gr.HTML()

        with gr.Column(variant='panel'):
            with gr.Tabs():
                # å¤§æ¨¡å‹é—®ç­”æ¨¡å—
                with gr.TabItem("å¤§æ¨¡å‹é—®ç­”æ¨¡å—"):
                    # æ ‡é¢˜
                    gr.Markdown("<div align='center'> <h3> æ–‡æ¡£å†…å®¹é—®ç­” </span> </h3> </div>")
                    # èŠå¤©æ¡†
                    chatbot = gr.Chatbot([], label="èŠå¤©æ¡†", elem_id="chatbot").style(height=850)
                    # é—®é¢˜å‘é€çª—å£
                    with gr.Row():
                        with gr.Column(scale=0.85):
                            msg_box = gr.Textbox(show_label=False, placeholder="è¯·è¾“å…¥é—®é¢˜ï¼š").style(container=False)
                        with gr.Column(scale=0.15):
                            msg_button = gr.Button("å‘é€é—®é¢˜", variant='primary')


    msg_button.click(fn=user, inputs=[msg_box, chatbot, file_dropdown], outputs=[msg_box, chatbot], queue=False
                     ).then(fn=bot, inputs=chatbot, outputs=chatbot)
    upload_button.upload(fn=add_file, inputs=[upload_button, file_dropdown], outputs=[file_dropdown, file_display])
    demo.load(load, inputs=file_dropdown, outputs=[file_dropdown, file_display])

if __name__ == "__main__":
    # app = gr.mount_gradio_app(app, demo, path="/")
    # uvicorn.run(app, host="0.0.0.0", port=9031)
    demo.queue().launch(server_name="127.0.0.1", server_port=9032, share=True)
